{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn import compose\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_log_error, median_absolute_error\n",
    "\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Data processing\n",
    "There is another notebook for EDA, we focus on modelling and evaluation part in this notebook. \n",
    "\n",
    "The data are from different data sources, the first step we need to do is to join the multiple data into one so we can train the model, the data size is big and we apply from tricks from Kaggle to reduce the dataset by changing the data type with less precision\n",
    "\n",
    "Since the data is time series data, we cannot do random sampling to split the data for train-test set. Moreover, sklearn capability restricts us to include all the training data, for example, random forest will try to build n_estimator trees for each training, which is linearly proportional to running time, it becomes worse if we try to do cross validation\n",
    "\n",
    "For our case, we include first 3 months as our training data and extra month as our testing data\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv('ashrae-energy-prediction/cleaned_weather_final.csv')\n",
    "building_df = pd.read_csv('ashrae-energy-prediction/building_metadata.csv')\n",
    "train_df = pd.read_csv('ashrae-energy-prediction/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  5.33 Mb (72.2% reduction)\n",
      "Mem. usage decreased to  0.03 Mb (60.3% reduction)\n",
      "Mem. usage decreased to 289.19 Mb (53.1% reduction)\n"
     ]
    }
   ],
   "source": [
    "# Data size reduction\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "weather_df = reduce_mem_usage(weather_df)\n",
    "building_df = reduce_mem_usage(building_df)\n",
    "train_df = reduce_mem_usage(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the data & create train-test set\n",
    "Below we try to join the data across 3 dataset.\n",
    "\n",
    "First, we use train_df as the base dataset to join building metadata using building_id as the key.\n",
    "\n",
    "Then we use the merged dataset to join weather data which is in site level by using site_id as the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building_id      20216100\n",
      "meter            20216100\n",
      "timestamp        20216100\n",
      "meter_reading    20216100\n",
      "site_id          20216100\n",
      "primary_use      20216100\n",
      "square_feet      20216100\n",
      "year_built        8088455\n",
      "floor_count       3506933\n",
      "dtype: int64\n",
      "\n",
      "building_id                          20112649\n",
      "meter                                20112649\n",
      "timestamp                            20112649\n",
      "meter_reading                        20112649\n",
      "site_id                              20112649\n",
      "primary_use                          20112649\n",
      "square_feet                          20112649\n",
      "year_built                            8007443\n",
      "floor_count                           3493975\n",
      "air_temperature                      20112649\n",
      "cloud_coverage                       19636096\n",
      "dew_temperature                      20112649\n",
      "precip_depth_1_hr                    18466551\n",
      "sea_level_pressure                   19333454\n",
      "wind_direction                       20112649\n",
      "wind_speed                           20112649\n",
      "temp_rank                            20112649\n",
      "offset                               20112649\n",
      "air_temperature_outliers_label       20112649\n",
      "cloud_coverage_outliers_label        20112649\n",
      "dew_temperature_outliers_label       20112649\n",
      "precip_depth_1_hr_outliers_label     20112649\n",
      "sea_level_pressure_outliers_label    20112649\n",
      "wind_direction_outliers_label        20112649\n",
      "wind_speed_outliers_label            20112649\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join different data together\n",
    "\n",
    "tmp = train_df.merge(building_df, on='building_id', how='inner')\n",
    "print(tmp.count())\n",
    "print('')\n",
    "\n",
    "tmp2 = tmp.merge(weather_df, on=['site_id', 'timestamp'], how='inner')\n",
    "print(tmp2.count())\n",
    "print('')\n",
    "\n",
    "merged_data = tmp2[['building_id', 'meter', 'timestamp', 'meter_reading', 'site_id',\n",
    "       'primary_use', 'square_feet', 'air_temperature', 'dew_temperature','wind_direction',\n",
    "       'wind_speed', 'air_temperature_outliers_label','dew_temperature_outliers_label',\n",
    "       'wind_direction_outliers_label', 'wind_speed_outliers_label']]\n",
    "\n",
    "merged_data.head(3)\n",
    "\n",
    "del tmp, tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Based on what we learned from EDA, it is time to apply transformation to the dataset (*some transformation are done to individual data already, this is transformation to the combined data)\n",
    "\n",
    "Below we mainly focus on the time related data, we create features such as hour & weekday based on timestamp provided\n",
    "\n",
    "We also apply log transformation to square feet to narrow the data range\n",
    "\n",
    "Moreover, for first 4 months of the data, we observe there many abnormally zero in site 0, 13 and 15. Since our data only cover this 4 months, it is better for us to remove them from the data, otherwise our model will try to learn many zeros readings from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Feature creation and remove abnormal sites\n",
    "\n",
    "def transform(df):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['hour'] = np.uint8(df['timestamp'].dt.hour)\n",
    "    df['day'] = np.uint8(df['timestamp'].dt.day)\n",
    "    df['weekday'] = np.uint8(df['timestamp'].dt.weekday)\n",
    "    df['month'] = np.uint8(df['timestamp'].dt.month)\n",
    "    df['square_feet'] = np.log(df['square_feet'])\n",
    "    return df\n",
    "\n",
    "training_set = transform(training_set)\n",
    "testing_set = transform(testing_set)\n",
    "\n",
    "removed_site = [0, 13, 15]\n",
    "training_set = training_set.loc[~training_set.site_id.isin(removed_site)]\n",
    "testing_set = testing_set.loc[~testing_set.site_id.isin(removed_site)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "Since we don't have labels for test set yet & sklearn is slow to process such amount of data, we restrict the data size by focusing on first 3 months as our training data (Jan - Mar) and an extra month as testing data (Apr), we do it in this order because **it is time series data, we cannot split the data by random sampling**\n",
    "\n",
    "\n",
    "The training data contains ~4.7M records and testing data contains ~1.7M records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4692951, 15)\n",
      "(1682838, 15)\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "\n",
    "mask = (merged_data['timestamp'] > '2016-01-01') & (merged_data['timestamp'] <= '2016-03-31')\n",
    "training_set = merged_data[mask]\n",
    "print(training_set.shape)\n",
    "\n",
    "mask = (merged_data['timestamp'] > '2016-04-01') & (merged_data['timestamp'] <= '2016-04-31')\n",
    "testing_set = merged_data[mask]\n",
    "print(testing_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into features & targets, then we apply the log transformation to target column because the range is huge. It is better to modify the distribution and do the training first, then we can reverse the log transformation when we do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features matrix and target column\n",
    "\n",
    "X_train = training_set.drop(['timestamp', 'meter_reading'], axis=1)\n",
    "y_train = training_set[['meter_reading']].values.ravel()\n",
    "\n",
    "X_test = testing_set.drop(['timestamp', 'meter_reading'], axis=1)\n",
    "y_test = testing_set[['meter_reading']].values.ravel()\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "del training_set, testing_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------\n",
    "# 2. Pipeline & Modeling\n",
    "This part we will create pipeline for the regression models and evaluate it\n",
    "\n",
    "We apply standardization to numerical features for distance-aware models such as linear regression\n",
    "\n",
    "Then we apply one hot encoding to building usage and expect different building usages will guide the model training\n",
    "# --------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(regressor=None):\n",
    "    \"Create a single pipeline that processing the data and then fits the regressor.\" \n",
    "\n",
    "    # numeric features  \n",
    "    numeric_features = ['square_feet', 'air_temperature', 'dew_temperature', 'wind_direction', 'wind_speed']\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scl', preprocessing.StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    # categorical features\n",
    "    categorical_features = ['primary_use']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    \n",
    "    # combine\n",
    "    preprocessor = compose.ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)]\n",
    "        ,remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', regressor)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics we use:\n",
    "### Root Mean Square Log Error (North Star Metric)\n",
    "To summarize the difference b/w log(prediction) and log(actual), it is suitable for our case because meter readings range from single digit to tens of thousands\n",
    "\n",
    "### Median Absolute Error\n",
    "To interpret the result using the same unit (meter unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Linear Regression with L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6343 RMSLE on test dataset\n",
      "44.7463 MedAE on test dataset\n"
     ]
    }
   ],
   "source": [
    "regressor = Ridge(normalize=False)\n",
    "\n",
    "pipeline = make_pipeline(regressor)\n",
    "\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred = np.expm1(pipeline.predict(X_test))\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "medae_test = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "print(f\"{medae_test:.4f} RMSLE on test dataset\")\n",
    "\n",
    "medae_test = median_absolute_error(y_test, y_pred)\n",
    "print(f\"{medae_test:.4f} MedAE on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model obtains 1.63 RMSLE & 44.75 MedAE\n",
    "\n",
    "In our scenario, the prediction error is 44.75 meter units off in median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9815 RMSLE on test dataset\n",
      "11.8224 MedAE on test dataset\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=5,\n",
    "                                  min_samples_leaf=200)\n",
    "\n",
    "pipeline = make_pipeline(regressor)\n",
    "\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred = np.expm1(pipeline.predict(X_test))\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "medae_test = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "print(f\"{medae_test:.4f} RMSLE on test dataset\")\n",
    "\n",
    "medae_test = median_absolute_error(y_test, y_pred)\n",
    "print(f\"{medae_test:.4f} MedAE on test dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest without many tuning push the number down to 0.98 RMSLE and 11.82 MedAE which is a great improvement comparing with our baseline linear model\n",
    "\n",
    "In our scenario, the prediction error is 11.82 meter units off in median, only quarter of the ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***!!!Time Consuming!!!*** Hyperparameter tuning for Random Forest ***!!!Time Consuming!!!***\n",
    "\n",
    "### !!!Be careful if you really run it\n",
    "\n",
    "This is very time consuming even for simple search space & limited iteration, **it takes literally ~5 hours to compute**, this suggests why we cannot use the whole data, even quarter of it can takes sklearn 5 hours to do cross validation for random forest.\n",
    "\n",
    "This also implies for bigger dataset, we may need to use package other than sklearn such as lightgbm & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9679 RMSLE on test dataset\n",
      "11.3171 MedAE on test dataset\n",
      "17515.99971985817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['pipeline.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "param_dist = {\"n_estimators\": [i for i in range(10, 50, 5)],\n",
    "          \"min_samples_leaf\": [i for i in range(50, 200, 20)],\n",
    "        }\n",
    "\n",
    "regressor = RandomizedSearchCV(clf\n",
    "                               ,param_distributions=param_dist\n",
    "                               ,n_iter=5\n",
    "                               ,cv=5\n",
    "                               ,scoring=\"neg_mean_squared_log_error\"\n",
    "                              )\n",
    "\n",
    "pipeline = make_pipeline(regressor)\n",
    "\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "\n",
    "y_pred = np.expm1(pipeline.predict(X_test))\n",
    "y_pred[y_pred < 0] = 0\n",
    "\n",
    "medae_test = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "print(f\"{medae_test:.4f} RMSLE on test dataset\")\n",
    "\n",
    "medae_test = median_absolute_error(y_test, y_pred)\n",
    "print(f\"{medae_test:.4f} MedAE on test dataset\")\n",
    "\n",
    "time_end = time.time()\n",
    "\n",
    "print(time_end - time_start)\n",
    "\n",
    "dump(pipeline, 'pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with hyperparameters tuning push the number down to 0.968 RMSLE and 11.32 MedAE which outperforms our previous random forest model.\n",
    "\n",
    "In our scenario, the prediction error is 11.82 meter units off in median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "In this project we have created a machine learning model using random forest to predict energy meter consumption, for the nature of time series data, we did sequential split of the data and keep the first three months as training data and an extra month as testing data.\n",
    "\n",
    "We used linear model as our baseline followed by random forest. With hyperparameter tuning, we achieved 0.9679 RMSLE on test dataset (Kaggle leaderboard No.1 is around 0.93, although it is not directly compariable because of different dataset, this shows the order of magnitude of our solution is close to the mainstream). Median Absolute Error is only 11.32 meters units.\n",
    "\n",
    "## Learnings:\n",
    "\n",
    "From this project, it is a great opportunities for us to learn how to process the real world data.\n",
    "\n",
    "-Data cleaning and EDA took more time than we expect and it is the most important to understand the problem\n",
    "\n",
    "-Visualization is cruical to spot the patterns from data\n",
    "\n",
    "-Data transformation is iteration, we need to explore and finetune all the time\n",
    "\n",
    "-Model and evaluation is straightforward if we have solid pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
